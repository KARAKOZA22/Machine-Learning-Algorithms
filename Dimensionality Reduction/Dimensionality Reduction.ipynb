{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dimensionality reduction** speeds up the training by making less features, but it cause loss of informations, that will make your model predict slightly worse, reducing the dimensionality of the training data may filter out some noise, and unnecessary details and thus result in higher performance, but in general it won’t it will just speed up training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more dimensions the training set has, the greater the risk of overfitting it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Approaches for Dimensionality Reduction\n",
    "1- Projection <br>\n",
    "when the dimensions are lower, the data points will be closer to each other"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![download](https://user-images.githubusercontent.com/96451039/228697500-3477df0e-d035-49aa-b6af-31771ea76337.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue instances are closer to each other than red ones as they are projected from 3D to 2D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Mainfold <br>\n",
    "However, projection is not always the best approach to dimensionality\n",
    "reduction. In many cases the subspace may twist and turn."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![download](https://user-images.githubusercontent.com/96451039/228697534-07fc95f5-b9ca-4d92-9ee6-a433f13940a9.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we used projection it will be the worst choice as the layers will overlap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![download](https://user-images.githubusercontent.com/96451039/228697665-966c022e-704d-4a55-b02a-bf437b275e45.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the left this is the result of projection, while on the right is the mainfold, it is rolled and twisted in higher dimension, and resembles a 2D plane "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PCA** the most popular dimensionality reduction algorithm <br>\n",
    "First it identifies the hyperplane that lies closest to the data, and then it projects the data onto it. <br>\n",
    "The simple idea behind PCA is to select maximum variance because it will lead minimum loss of information, and it minimizes the distance between dataset, and its projection onto that axis <br>\n",
    "So , as we see in the figure below the top of right hand is maximum variance, middle intermediate variance, bottom least variance, so as the variance decreases, the loss of information increases so, we choosed the maximum ones.<br>\n",
    "To summarize: you are trying to take the hyperplane that maximum number of data points lies on it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![download](https://user-images.githubusercontent.com/96451039/228697716-df1ad668-b662-4544-a1fb-d385d95e144e.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = random.sample(range(0,200),200)\n",
    "x2 = random.sample(range(0,200),200)\n",
    "x3 = random.sample(range(0,200),200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>63</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>120</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139</td>\n",
       "      <td>135</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1   x2   x3\n",
       "0  138   10   22\n",
       "1  106   63  176\n",
       "2  101  120  130\n",
       "3   95   39   13\n",
       "4  139  135   83"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'x1':x1,'x2':x2,'x3':x3})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can find the principal component of training set by svd \n",
    "# PCA assumes that the dataset is centered around the origin.\n",
    "df_centered = df - df.mean(axis=0)\n",
    "U, s, Vt = np.linalg.svd(df_centered)\n",
    "c1 = Vt[0]\n",
    "c2 = Vt[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1324852 , -0.68717324, -0.71431129],\n",
       "       [ 0.95563881,  0.27982202, -0.0919462 ],\n",
       "       [-0.263063  ,  0.67044208, -0.69376169]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# principal vectors are 3*3, so we will take first 2 to make the dataset into 2D instead of 3D\n",
    "Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1324852  -0.68717324 -0.71431129] [ 0.95563881  0.27982202 -0.0919462 ]\n"
     ]
    }
   ],
   "source": [
    "print(c1,c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = Vt[:2].T\n",
    "df_2D = df_centered @ W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121.961810</td>\n",
       "      <td>18.873854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-28.701836</td>\n",
       "      <td>-11.035736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-35.674818</td>\n",
       "      <td>4.365451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102.765724</td>\n",
       "      <td>-13.276261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-7.375348</td>\n",
       "      <td>49.198527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1\n",
       "0  121.961810  18.873854\n",
       "1  -28.701836 -11.035736\n",
       "2  -35.674818   4.365451\n",
       "3  102.765724 -13.276261\n",
       "4   -7.375348  49.198527"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2D.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using sklearn it handles whether the data is around origin or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121.961810</td>\n",
       "      <td>18.873854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-28.701836</td>\n",
       "      <td>-11.035736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-35.674818</td>\n",
       "      <td>4.365451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102.765724</td>\n",
       "      <td>-13.276261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-7.375348</td>\n",
       "      <td>49.198527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1\n",
       "0  121.961810  18.873854\n",
       "1  -28.701836 -11.035736\n",
       "2  -35.674818   4.365451\n",
       "3  102.765724 -13.276261\n",
       "4   -7.375348  49.198527"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "df_2D = pd.DataFrame(pca.fit_transform(df))\n",
    "df_2D.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3602933, 0.3349831])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the variance on the Principal Component --> information of each axis, here it decides to drop the least column that benefit model\n",
    "# which has approximatly 0.3 of informations, in example like this we wont apply PCA, it is just for practicing\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121.961810</td>\n",
       "      <td>18.873854</td>\n",
       "      <td>-16.365960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-28.701836</td>\n",
       "      <td>-11.035736</td>\n",
       "      <td>-79.253815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-35.674818</td>\n",
       "      <td>4.365451</td>\n",
       "      <td>-7.810263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102.765724</td>\n",
       "      <td>-13.276261</td>\n",
       "      <td>20.632424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-7.375348</td>\n",
       "      <td>49.198527</td>\n",
       "      <td>24.856773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2\n",
       "0  121.961810  18.873854 -16.365960\n",
       "1  -28.701836 -11.035736 -79.253815\n",
       "2  -35.674818   4.365451  -7.810263\n",
       "3  102.765724 -13.276261  20.632424\n",
       "4   -7.375348  49.198527  24.856773"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can keep the percentage of information you need by doing the following\n",
    "pca = PCA(n_components=0.95)\n",
    "df_2D = pd.DataFrame(pca.fit_transform(df))\n",
    "df_2D.head()\n",
    "# so to keep 95% of information u cant apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get back dropped or compressed columns u can use inverse_transform()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the difference is the quality but the numbers can be detected easily too."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![download](https://user-images.githubusercontent.com/96451039/228697816-b1db1e87-295d-434d-8e88-373b895a0996.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, svd_solver is actually set to \"auto\": Scikit-Learn automatically uses\n",
    "the randomized PCA algorithm if max(m, n) > 500 and n_components is an integer\n",
    "smaller than 80% of min(m, n), or else it uses the full SVD approach. So the preceding\n",
    "code would use the randomized PCA algorithm even if you removed the\n",
    "svd_solver=\"randomized\" argument, since 154 < 0.8 × 784. If you want to force\n",
    "Scikit-Learn to use full SVD for a slightly more precise result, you can set the\n",
    "svd_solver hyperparameter to \"full\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
